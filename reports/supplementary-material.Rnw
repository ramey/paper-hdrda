\documentclass[11pt]{article}
\usepackage{graphicx, amsmath, amssymb, bm, url, mathtools, natbib, amsthm, setspace}

\pagestyle{plain}
%----------------Page dimensions ----------------
\oddsidemargin 0.0in
\evensidemargin 0.0in
\topmargin -0.75in
\leftmargin 0in
\headheight 0.0in
\headsep 0.5in
%\footheight 0.0in
\footskip 0.5in
\footnotesep 0.0in
\textwidth 6.7in
\textheight 9.5in
%-----------Define Pictures---------------------
\def\picture #1 by #2 (#3){
 \vbox to #2{
   \hrule width #1 height 0pt depth 0pt
   \vfill
   \special{picture #3} % this is the low-level interface
   }
 }
\def\scaledpicture #1 by #2 (#3 scaled #4){{
 \dimen0=#1 \dimen1=#2
 \divide\dimen0 by 1000 \multiply\dimen0 by #4
 \divide\dimen1 by 1000 \multiply\dimen1 by #4
 \picture \dimen0 by \dimen1 (#3 scaled #4)}
 }

\newcommand{\xbar}{\bar{x}}
\newcommand{\tr}{\text{tr}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\title{Supplementary Material for ``High-Dimensional Regularized Discriminant Analysis''}

\author{John A. Ramey, Caleb K. Stein, and Dean M. Young}

<<knitr_setup, include=FALSE, echo=FALSE, cache=FALSE>>=
# Round digits throughout document including \Sexpr statements.
# See Yihui's response here:
# http://stackoverflow.com/questions/11062497/how-to-avoid-using-round-in-every-sexpr
options(digits = 3)

opts_chunk$set(fig.align = 'default', dev = 'png', message = FALSE,
               warning = FALSE, cache = TRUE, echo = FALSE, autodep = TRUE,
               fig.width = 12, fig.height = 12, out.width = "\\linewidth")
@ 
  
<<setup>>=
setwd("..")
library(ProjectTemplate)
load.project()

results <- lapply(results, function(res) {
  res <- lapply(res, function(res_d) {
    errors <- do.call(cbind, res_d$errors)
    res_d[["errors"]] <- NULL
    cbind(do.call(cbind, res_d), errors)
  })
  do.call(rbind, res)
})
results <- data.frame(do.call(rbind, results), stringsAsFactors = FALSE)

results$lambda <- as.numeric(results$lambda)
results$gamma <- as.numeric(results$gamma)
results$Dudoit <- as.numeric(results$Dudoit)
results$HDRDA <- as.numeric(results$HDRDA)
results$Guo <- as.numeric(results$Guo)
results$Pang <- as.numeric(results$Pang)
results$Tong <- as.numeric(results$Tong)
results$Witten <- as.numeric(results$Witten)

# To abide by Biometrika's requirements of no abbreviations, we rename the
# results of our HDRDA classifier as simply "Ours."
results$Ours <- results$HDRDA
results <- subset(results, select = -HDRDA)

results$d <- factor(results$d, labels = sort(unique(as.numeric(results$d))))

# Summary of the classification error rates for each data set and number of
# variables selected, d.
error_rates <- subset(results, select = -c(lambda, gamma))
m_error <- melt(error_rates, variable.name = "Classifier", value.name = "Error")
m_error$Classifier <- factor(m_error$Classifier)
error_rates <- ddply(m_error, .(data_set, d, Classifier), plyr:::summarize,
                     Avg_Error = mean(Error), Num_Reps = length(Error))
error_rates <- ddply(error_rates, .(data_set, d, Classifier), transform,
                     SE_Error = sqrt(Avg_Error * (1 - Avg_Error) / Num_Reps))
error_rates <- subset(error_rates, select = -Num_Reps)

# Candidate values of tuning parameters.
seq_lambda <- seq(0, 1, by = 0.05)
seq_gamma <- 10^seq.int(-1, 5)

# Summary of the optimal tuning-parameter estimates for each data set and number
# of variables selected, d.
hdrda_optimal <- subset(results, select = c(data_set, d, lambda, gamma))
hdrda_optimal$lambda <- factor(hdrda_optimal$lambda, levels = seq_lambda)
hdrda_optimal$gamma <- factor(hdrda_optimal$gamma, levels = seq_gamma)

hdrda_optimal <- ddply(hdrda_optimal, .(data_set, d), function(x) {
  x <- subset(x, select = c(lambda, gamma))
  melt(table(x))
})

@ 

\begin{document}

\doublespacing

\maketitle

\begin{figure}
<<optimal_estimates_burczynski>>=
hdrda_optimal$lambda <- factor(hdrda_optimal$lambda)
hdrda_optimal$gamma <- factor(hdrda_optimal$gamma)
p <- ggplot(subset(hdrda_optimal, data_set == "burczynski" & d %in% c(100, 500, 1000)), aes(lambda))
p <- p + geom_bar(aes(fill = gamma, weight = value))
p <- p + facet_grid(d ~ ., labeller = label_bquote(d == .(x))) + theme_bw()
p <- p + theme(strip.text.y = element_text(size = 16))
p <- p + theme(axis.text = element_text(size = 16))
p <- p + theme(axis.title.x = element_text(size = 24))
p <- p + theme(axis.title.y = element_text(size = 20))
p <- p + scale_fill_discrete(name = expression(gamma))
p <- p + theme(legend.title = element_text(size = 28))
p <- p + theme(legend.key.size = unit(1.25, "cm"))
p <- p + theme(legend.text = element_text(size = 18))
p + xlab(expression(lambda)) + ylab("Counts")
@ 
\caption{Counts of the optimal tuning-parameter estimates for the \emph{HDRDA}
  classifier for the Burczynski data set for $d = 100$, $500$, and $1000$.}
\label{fig:optimal-burczynski}
\end{figure}

\begin{figure}
<<optimal_estimates_nakayama>>=
hdrda_optimal$lambda <- factor(hdrda_optimal$lambda)
hdrda_optimal$gamma <- factor(hdrda_optimal$gamma)
p <- ggplot(subset(hdrda_optimal, data_set == "nakayama" & d %in% c(100, 500, 1000)), aes(lambda))
p <- p + geom_bar(aes(fill = gamma, weight = value))
p <- p + facet_grid(d ~ ., labeller = label_bquote(d == .(x))) + theme_bw()
p <- p + theme(strip.text.y = element_text(size = 16))
p <- p + theme(axis.text = element_text(size = 16))
p <- p + theme(axis.title.x = element_text(size = 24))
p <- p + theme(axis.title.y = element_text(size = 20))
p <- p + scale_fill_discrete(name = expression(gamma))
p <- p + theme(legend.title = element_text(size = 28))
p <- p + theme(legend.key.size = unit(1.25, "cm"))
p <- p + theme(legend.text = element_text(size = 18))
p + xlab(expression(lambda)) + ylab("Counts")
@ 
\caption{Counts of the optimal tuning-parameter estimates for the \emph{HDRDA}
  classifier for the Nakayama data set for $d = 100$, $500$, and $1000$.}
\label{fig:optimal-nakayama}
\end{figure}

\begin{figure}
<<optimal_estimates_shipp>>=
hdrda_optimal$lambda <- factor(hdrda_optimal$lambda)
hdrda_optimal$gamma <- factor(hdrda_optimal$gamma)
p <- ggplot(subset(hdrda_optimal, data_set == "shipp" & d %in% c(100, 500, 1000)), aes(lambda))
p <- p + geom_bar(aes(fill = gamma, weight = value))
p <- p + facet_grid(d ~ ., labeller = label_bquote(d == .(x))) + theme_bw()
p <- p + theme(strip.text.y = element_text(size = 16))
p <- p + theme(axis.text = element_text(size = 16))
p <- p + theme(axis.title.x = element_text(size = 24))
p <- p + theme(axis.title.y = element_text(size = 20))
p <- p + scale_fill_discrete(name = expression(gamma))
p <- p + theme(legend.title = element_text(size = 28))
p <- p + theme(legend.key.size = unit(1.25, "cm"))
p <- p + theme(legend.text = element_text(size = 18))
p + xlab(expression(lambda)) + ylab("Counts")
@ 
\caption{Counts of the optimal tuning-parameter estimates for the \emph{HDRDA}
  classifier for the Shipp data set for $d = 100$, $500$, and $1000$.}
\label{fig:optimal-shipp}
\end{figure}

\begin{figure}
<<optimal_estimates_singh>>=
hdrda_optimal$lambda <- factor(hdrda_optimal$lambda)
hdrda_optimal$gamma <- factor(hdrda_optimal$gamma)
p <- ggplot(subset(hdrda_optimal, data_set == "singh" & d %in% c(100, 500, 1000)), aes(lambda))
p <- p + geom_bar(aes(fill = gamma, weight = value))
p <- p + facet_grid(d ~ ., labeller = label_bquote(d == .(x))) + theme_bw()
p <- p + theme(strip.text.y = element_text(size = 16))
p <- p + theme(axis.text = element_text(size = 16))
p <- p + theme(axis.title.x = element_text(size = 24))
p <- p + theme(axis.title.y = element_text(size = 20))
p <- p + scale_fill_discrete(name = expression(gamma))
p <- p + theme(legend.title = element_text(size = 28))
p <- p + theme(legend.key.size = unit(1.25, "cm"))
p <- p + theme(legend.text = element_text(size = 18))
p + xlab(expression(lambda)) + ylab("Counts")
@ 
\caption{Counts of the optimal tuning-parameter estimates for the \emph{HDRDA}
  classifier for the Singh data set for $d = 100$, $500$, and $1000$.}
\label{fig:optimal-singh}
\end{figure}



\end{document} 
